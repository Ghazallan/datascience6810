{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3e0616-512a-4bcf-9176-7bc4d2a6d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17980921-1180-4094-bac2-dad1886a7d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180492982dee4e88bdb86ce9f0698691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.79\n",
      "Recall: 0.68\n",
      "F1 Score: 0.73\n",
      "MCC: 0.65\n",
      "AUC: 0.91\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      2447\n",
      "           1       0.79      0.68      0.73       897\n",
      "\n",
      "    accuracy                           0.87      3344\n",
      "   macro avg       0.84      0.81      0.82      3344\n",
      "weighted avg       0.86      0.87      0.86      3344\n",
      "\n",
      "ðŸƒ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/0/runs/01a1f08bf6354c7fb9bd789b0ed5cef8\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85b90e92e5b4943841a422c83a7989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree:\n",
      "Accuracy: 0.97\n",
      "Precision: 0.94\n",
      "Recall: 0.95\n",
      "F1 Score: 0.94\n",
      "MCC: 0.92\n",
      "AUC: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2447\n",
      "           1       0.94      0.95      0.94       897\n",
      "\n",
      "    accuracy                           0.97      3344\n",
      "   macro avg       0.96      0.96      0.96      3344\n",
      "weighted avg       0.97      0.97      0.97      3344\n",
      "\n",
      "ðŸƒ View run Decision Tree at: http://127.0.0.1:5000/#/experiments/0/runs/cddb43f05df1430eaa3f928c7dc3578b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5999a4b1e0f4f2d9e52db1311a183a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.96\n",
      "F1 Score: 0.97\n",
      "MCC: 0.96\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2447\n",
      "           1       0.99      0.96      0.97       897\n",
      "\n",
      "    accuracy                           0.99      3344\n",
      "   macro avg       0.99      0.98      0.98      3344\n",
      "weighted avg       0.99      0.99      0.99      3344\n",
      "\n",
      "ðŸƒ View run Random Forest at: http://127.0.0.1:5000/#/experiments/0/runs/cbd0a2a6f07f4fd89a4c7b6e47206b09\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bcee6d90f04adaafd29f2e72a0d8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Extra Trees Classifier:\n",
      "Accuracy: 0.99\n",
      "Precision: 1.00\n",
      "Recall: 0.95\n",
      "F1 Score: 0.97\n",
      "MCC: 0.97\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2447\n",
      "           1       1.00      0.95      0.97       897\n",
      "\n",
      "    accuracy                           0.99      3344\n",
      "   macro avg       0.99      0.98      0.98      3344\n",
      "weighted avg       0.99      0.99      0.99      3344\n",
      "\n",
      "ðŸƒ View run Extra Trees Classifier at: http://127.0.0.1:5000/#/experiments/0/runs/6d48afbfac584cc8a55c99eb505a7caa\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cd4de7f41645818ffb121a576da3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AdaBoost:\n",
      "Accuracy: 0.97\n",
      "Precision: 0.93\n",
      "Recall: 0.95\n",
      "F1 Score: 0.94\n",
      "MCC: 0.92\n",
      "AUC: 0.96\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2447\n",
      "           1       0.93      0.95      0.94       897\n",
      "\n",
      "    accuracy                           0.97      3344\n",
      "   macro avg       0.96      0.96      0.96      3344\n",
      "weighted avg       0.97      0.97      0.97      3344\n",
      "\n",
      "ðŸƒ View run AdaBoost at: http://127.0.0.1:5000/#/experiments/0/runs/01e40534c9bb42a7b754152f39b5ddcb\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b33af956e99475c8081a2ffb8e8b337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for XGBoost:\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.96\n",
      "F1 Score: 0.97\n",
      "MCC: 0.96\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2447\n",
      "           1       0.99      0.96      0.97       897\n",
      "\n",
      "    accuracy                           0.99      3344\n",
      "   macro avg       0.99      0.98      0.98      3344\n",
      "weighted avg       0.99      0.99      0.99      3344\n",
      "\n",
      "ðŸƒ View run XGBoost at: http://127.0.0.1:5000/#/experiments/0/runs/5344c6ddb26242e08859626716a93b1a\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed0e55c0823455bb52683b184167701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for CatBoost:\n",
      "Accuracy: 0.99\n",
      "Precision: 1.00\n",
      "Recall: 0.95\n",
      "F1 Score: 0.97\n",
      "MCC: 0.97\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2447\n",
      "           1       1.00      0.95      0.97       897\n",
      "\n",
      "    accuracy                           0.99      3344\n",
      "   macro avg       0.99      0.98      0.98      3344\n",
      "weighted avg       0.99      0.99      0.99      3344\n",
      "\n",
      "ðŸƒ View run CatBoost at: http://127.0.0.1:5000/#/experiments/0/runs/92b318412efa489cbbbb45634cee4abd\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa961d4d533f488a85ac63ea0646b5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVM:\n",
      "Accuracy: 0.73\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 Score: 0.00\n",
      "MCC: 0.00\n",
      "AUC: 0.81\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85      2447\n",
      "           1       0.00      0.00      0.00       897\n",
      "\n",
      "    accuracy                           0.73      3344\n",
      "   macro avg       0.37      0.50      0.42      3344\n",
      "weighted avg       0.54      0.73      0.62      3344\n",
      "\n",
      "ðŸƒ View run SVM at: http://127.0.0.1:5000/#/experiments/0/runs/291169db04ba453194868e25b6cf340e\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acde5f32766542689a22aedb8f300a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNN:\n",
      "Accuracy: 0.75\n",
      "Precision: 0.56\n",
      "Recall: 0.41\n",
      "F1 Score: 0.47\n",
      "MCC: 0.32\n",
      "AUC: 0.72\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84      2447\n",
      "           1       0.56      0.41      0.47       897\n",
      "\n",
      "    accuracy                           0.75      3344\n",
      "   macro avg       0.68      0.64      0.66      3344\n",
      "weighted avg       0.74      0.75      0.74      3344\n",
      "\n",
      "ðŸƒ View run KNN at: http://127.0.0.1:5000/#/experiments/0/runs/91a2e4679f044f02a519ef6e2403409e\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ddecd4c7ca4e5eb1b1df354a59b4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Naive Bayes:\n",
      "Accuracy: 0.98\n",
      "Precision: 1.00\n",
      "Recall: 0.94\n",
      "F1 Score: 0.96\n",
      "MCC: 0.95\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2447\n",
      "           1       1.00      0.94      0.96       897\n",
      "\n",
      "    accuracy                           0.98      3344\n",
      "   macro avg       0.99      0.97      0.98      3344\n",
      "weighted avg       0.98      0.98      0.98      3344\n",
      "\n",
      "ðŸƒ View run Naive Bayes at: http://127.0.0.1:5000/#/experiments/0/runs/4364e9fa12504156b8576d714f9d86ee\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadis\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Users\\hadis\\OneDrive\\My One Drive (Hadiseh)\\H Documents\\Datascience-Seminar\\churn\\Dataset\\Databel - Data.csv')\n",
    "\n",
    "# Select features and target\n",
    "column_selection = df[['Churn Label', 'Account Length (in months)', 'Local Calls', 'Local Mins', 'Intl Calls', 'Intl Mins',\n",
    "                       'Intl Active', 'Intl Plan', 'Extra International Charges', 'Customer Service Calls', 'Avg Monthly GB Download',\n",
    "                       'Unlimited Data Plan', 'Extra Data Charges', 'Gender', 'Age', 'Under 30', 'Senior', 'Group',\n",
    "                       'Number of Customers in Group', 'Device Protection & Online Backup', 'Contract Type', 'Payment Method',\n",
    "                       'Monthly Charge', 'Total Charges', 'Churn Category', 'Churn Reason']]\n",
    "\n",
    "features = column_selection.drop('Churn Label', axis=1)\n",
    "X = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "# Encode the target variable (Churn Label) \n",
    "y = df['Churn Label']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define the models to compare\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Extra Trees Classifier\": ExtraTreesClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, random_seed=42, verbose=False),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Loop through the models and log each one in MLflow\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        probabilities = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "        mcc = matthews_corrcoef(y_test, predictions)\n",
    "        auc = roc_auc_score(y_test, probabilities) if probabilities is not None else None\n",
    "\n",
    "        # Log parameters and metrics with MLflow\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"mcc\", mcc)\n",
    "        if auc is not None:\n",
    "            mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "        # Log confusion matrix as an artifact\n",
    "        confusion_mat = confusion_matrix(y_test, predictions)\n",
    "        np.save(f\"confusion_matrix_{model_name}.npy\", confusion_mat)\n",
    "        mlflow.log_artifact(f\"confusion_matrix_{model_name}.npy\")\n",
    "\n",
    "        # Log the model\n",
    "        input_example = X_train.iloc[0].values.reshape(1, -1)  \n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\", input_example=input_example)\n",
    "\n",
    "        # Print evaluation results\n",
    "        print(f\"Results for {model_name}:\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Precision: {precision:.2f}\")\n",
    "        print(f\"Recall: {recall:.2f}\")\n",
    "        print(f\"F1 Score: {f1:.2f}\")\n",
    "        print(f\"MCC: {mcc:.2f}\")\n",
    "        if auc is not None:\n",
    "            print(f\"AUC: {auc:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd881e-3d61-4971-a807-4ba22c98bfed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
